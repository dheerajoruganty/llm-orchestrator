experiment_name,payload_file,instance_type,instance_count,concurrency,error_rate,prompt_token_count_mean,prompt_token_throughput,completion_token_count_mean,completion_token_throughput,latency_p50,latency_p95,latency_p99,transactions_per_minute,price_per_txn,price_per_token,score_dict,score,any_criterion_failed,error_rate_criterion_failed,latency_criterion_failed,cost_per_txn_criterion_failed,error_rate_text,latency_p95_text,price_per_10k_txn_text
llama3-8b-instruct,payload_en_1-500.jsonl,g5.2xlarge,1.0,1,0.0,284,4314,61,76,2.96,2.96,2.96,911,2.217343578485181e-05,0.00000006,"{'score': 2.988913282107574, 'any_criterion_failed': True, 'error_rate_criterion_failed': False, 'latency_criterion_failed': True, 'cost_per_txn_criterion_failed': False, 'error_rate_text': ""<span style='color:green'>0.00</span>"", 'latency_p95_text': ""<span style='color:red'>**2.96**</span>"", 'price_per_10k_txn_text': ""<span style='color:green'>0.22</span>""}",2.988913282107574,True,False,True,False,<span style='color:green'>0.00</span>,<span style='color:red'>**2.96**</span>,<span style='color:green'>0.22</span>
